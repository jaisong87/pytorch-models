{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from MNIST\n",
    "We download data from an online source(deeplearning.net) to local directory.\n",
    "The data is deserialized using pickle into tuples for train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "if not PATH.exists():\n",
    "    PATH.mkdir(parents=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), (x_test, y_test)) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape, x_train = (50000, 784), y_train = (50000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training set shape, x_train = {}, y_train = {}\".format(x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set shape, x_valid = (10000, 784), y_valid = (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Validation set shape, x_valid = {}, y_valid = {}\".format(x_valid.shape, y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape, x_test = (10000, 784), y_test = (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Test set shape, x_test = {}, y_test = {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display input with label\n",
    "In this section we write some utils to display input with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_example(x_train, y_train, N=0):\n",
    "    plt.imshow(x_train[N].reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.title(\"digit label = {}\".format(y_train[N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_example(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 50000 examples with 784 features each\n",
      "Training labels are in range [0, 9]\n"
     ]
    }
   ],
   "source": [
    "n, c = x_train.shape\n",
    "print(\"Training set has {} examples with {} features each\".format(n,c))\n",
    "print(\"Training labels are in range [{}, {}]\".format(y_train.min(), y_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN from scrath\n",
    "In this section, we implement a neural network without torch.nn\n",
    "using basic torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb, weights, bias):\n",
    "#    return log_softmax(xb @ weights + bias)\n",
    "    return log_softmax(xb.mm(weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-2.4968, -2.6604, -2.9775, -2.3970, -1.8815, -1.9540, -1.8290, -2.3706,\n",
      "        -2.5417, -2.5381], grad_fn=<SelectBackward>), torch.Size([64, 10]))\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb, weights, bias)  # predictions\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3406, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training on initial weights = 2.31931591034%%\n",
      "Accuracy on validation  on initial weights = 2.31978702545%%\n",
      "Accuracy on training after epoch#0, loss = 0.326205164194, acc = 90.5159988403%%\n",
      "Accuracy on validation after epoch#0, loss = 0.30722245574, acc = 91.2799987793%%\n",
      "Accuracy on training after epoch#1, loss = 0.306680738926, acc = 91.1279983521%%\n",
      "Accuracy on validation after epoch#1, loss = 0.293733656406, acc = 91.7799987793%%\n",
      "Accuracy on training after epoch#2, loss = 0.297901064157, acc = 91.4659957886%%\n",
      "Accuracy on validation after epoch#2, loss = 0.2889072299, acc = 91.9000015259%%\n",
      "Accuracy on training after epoch#3, loss = 0.292455583811, acc = 91.5799942017%%\n",
      "Accuracy on validation after epoch#3, loss = 0.286613762379, acc = 92.0099945068%%\n",
      "Accuracy on training after epoch#4, loss = 0.28855574131, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#4, loss = 0.285406827927, acc = 92.0400009155%%\n"
     ]
    }
   ],
   "source": [
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print (\"Accuracy on training on initial weights = {}%%\".\n",
    "           format(loss_func(model(x_train, weights, bias), y_train), 100*accuracy(model(x_train, weights, bias), y_train)))\n",
    "    print (\"Accuracy on validation  on initial weights = {}%%\".\n",
    "           format( loss_func(model(x_valid, weights, bias), y_valid), 100*accuracy(model(x_valid, weights, bias), y_valid)))\n",
    "\n",
    "lr = 0.5\n",
    "bs = 64\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    for i in range (n/bs):\n",
    "        xb = x_train[i*bs:min(n, (i+1)*bs)]  # a mini-batch from x\n",
    "        yb = y_train[i*bs:min(n, (i+1)*bs)]\n",
    "        preds = model(xb, weights, bias)  # predictions\n",
    "        loss = loss_func(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print (\"Accuracy on training after epoch#{}, loss = {}, acc = {}%%\".\n",
    "               format(e, loss_func(model(x_train, weights, bias), y_train), 100*accuracy(model(x_train, weights, bias), y_train)))\n",
    "        print (\"Accuracy on validation after epoch#{}, loss = {}, acc = {}%%\".\n",
    "               format(e, loss_func(model(x_valid, weights, bias), y_valid), 100*accuracy(model(x_valid, weights, bias), y_valid)))\n",
    "    #    weights = weights - learning_rate * weights.grad\n",
    "    #    bias = bias - learning_rate * bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using torch.nn.functional\n",
    "In this section we refactor our above code and use functional package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy\n",
    "def forward(xb, weights, bias):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2854), tensor(0.9204))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(loss_func(forward(x_valid, weights, bias), y_valid), accuracy(forward(x_valid, weights, bias), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using functional package\n",
    "We repeat same exercise using functional package. Try to implement everything on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2.3208), tensor(0.0881))\n",
      "Accuracy on training on initial weights = 0.288550287485%%\n",
      "Accuracy on validation  on initial weights = 0.285406172276%%\n",
      "Accuracy on training after epoch#0, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#0, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#1, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#1, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#2, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#2, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#3, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#3, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#4, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#4, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#5, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#5, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#6, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#6, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#7, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#7, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#8, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#8, loss = 0.285406172276, acc = 92.0400009155%%\n",
      "Accuracy on training after epoch#9, loss = 0.288550287485, acc = 91.7320022583%%\n",
      "Accuracy on validation after epoch#9, loss = 0.285406172276, acc = 92.0400009155%%\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(784, 10) / math.sqrt(784.0)\n",
    "w.requires_grad_()\n",
    "b = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(loss_func(forward(x_valid, w, b), y_valid), accuracy(forward(x_valid, w, b), y_valid))\n",
    "\n",
    "with torch.no_grad():\n",
    "    print (\"Accuracy on training on initial weights = {}%%\".\n",
    "           format(loss_func(model(x_train, weights, bias), y_train), 100*accuracy(model(x_train, weights, bias), y_train)))\n",
    "    print (\"Accuracy on validation  on initial weights = {}%%\".\n",
    "           format( loss_func(model(x_valid, weights, bias), y_valid), 100*accuracy(model(x_valid, weights, bias), y_valid)))\n",
    "\n",
    "    \n",
    "lr = 0.5\n",
    "epochs = 10\n",
    "bs = 64\n",
    "for e in range(epochs):\n",
    "    for i in range(n/bs):\n",
    "        b_start = i*bs\n",
    "        b_end = min(n, (i+1)*bs)\n",
    "        xb = x_train[b_start:b_end]\n",
    "        yb = y_train[b_start:b_end]\n",
    "        pred = forward(xb, w, b)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad*lr\n",
    "            b -= b.grad*lr\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print (\"Accuracy on training after epoch#{}, loss = {}, acc = {}%%\".\n",
    "               format(e, loss_func(model(x_train, weights, bias), y_train), 100*accuracy(model(x_train, weights, bias), y_train)))\n",
    "        print (\"Accuracy on validation after epoch#{}, loss = {}, acc = {}%%\".\n",
    "               format(e, loss_func(model(x_valid, weights, bias), y_valid), 100*accuracy(model(x_valid, weights, bias), y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use nn module\n",
    "Now we use nn.module to encapsulate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MnistLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistLogistic, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return xb.mm(self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, x_train, y_train, x_valid, y_valid, bs = 64, lr = 0.5):\n",
    "    n, num_feats = x_train.shape\n",
    "    with torch.no_grad():\n",
    "        print (\"Accuracy on training on initial weights = {}%%\".\n",
    "               format(loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "        print (\"Accuracy on validation  on initial weights = {}%%\".\n",
    "               format( loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for i in range(n/bs):\n",
    "            b_start = i*bs\n",
    "            b_end = min(n, (i+1)*bs)\n",
    "            xb = x_train[b_start:b_end]\n",
    "            yb = y_train[b_start:b_end]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print (\"Accuracy on training after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "            print (\"Accuracy on validation after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training on initial weights = 2.39047789574%%\n",
      "Accuracy on validation  on initial weights = 2.38573241234%%\n",
      "Accuracy on training after epoch#0, loss = 0.325614720583, acc = 90.6180038452%%\n",
      "Accuracy on validation after epoch#0, loss = 0.306369125843, acc = 91.3699951172%%\n",
      "Accuracy on training after epoch#1, loss = 0.306063920259, acc = 91.2119979858%%\n",
      "Accuracy on validation after epoch#1, loss = 0.292879462242, acc = 91.7999954224%%\n",
      "Accuracy on training after epoch#2, loss = 0.297343254089, acc = 91.5039978027%%\n",
      "Accuracy on validation after epoch#2, loss = 0.288161635399, acc = 91.8699951172%%\n",
      "Accuracy on training after epoch#3, loss = 0.291963636875, acc = 91.6699981689%%\n",
      "Accuracy on validation after epoch#3, loss = 0.285972833633, acc = 91.9899978638%%\n",
      "Accuracy on training after epoch#4, loss = 0.288119226694, acc = 91.7340011597%%\n",
      "Accuracy on validation after epoch#4, loss = 0.284847646952, acc = 92.0899963379%%\n",
      "Accuracy on training after epoch#5, loss = 0.285144656897, acc = 91.8219985962%%\n",
      "Accuracy on validation after epoch#5, loss = 0.284267693758, acc = 92.1299972534%%\n",
      "Accuracy on training after epoch#6, loss = 0.282722204924, acc = 91.90599823%%\n",
      "Accuracy on validation after epoch#6, loss = 0.283997744322, acc = 92.1299972534%%\n",
      "Accuracy on training after epoch#7, loss = 0.280683875084, acc = 91.9339981079%%\n",
      "Accuracy on validation after epoch#7, loss = 0.283921897411, acc = 92.1500015259%%\n",
      "Accuracy on training after epoch#8, loss = 0.278927326202, acc = 92.0%%\n",
      "Accuracy on validation after epoch#8, loss = 0.283971071243, acc = 92.1699981689%%\n",
      "Accuracy on training after epoch#9, loss = 0.277382791042, acc = 92.0279998779%%\n",
      "Accuracy on validation after epoch#9, loss = 0.284105479717, acc = 92.1500015259%%\n"
     ]
    }
   ],
   "source": [
    "model = MnistLogistic()\n",
    "fit(model, x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MnistLogisticB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistLogisticB, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.fc1(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training on initial weights = 0.277382791042%%\n",
      "Accuracy on validation  on initial weights = 0.284105479717%%\n",
      "Accuracy on training after epoch#0, loss = 0.276008754969, acc = 92.0719985962%%\n",
      "Accuracy on validation after epoch#0, loss = 0.284299254417, acc = 92.1199951172%%\n",
      "Accuracy on training after epoch#1, loss = 0.274771183729, acc = 92.1180038452%%\n",
      "Accuracy on validation after epoch#1, loss = 0.284535437822, acc = 92.1199951172%%\n",
      "Accuracy on training after epoch#2, loss = 0.273644298315, acc = 92.1380004883%%\n",
      "Accuracy on validation after epoch#2, loss = 0.28479719162, acc = 92.1299972534%%\n",
      "Accuracy on training after epoch#3, loss = 0.272611320019, acc = 92.1760025024%%\n",
      "Accuracy on validation after epoch#3, loss = 0.285082489252, acc = 92.1699981689%%\n",
      "Accuracy on training after epoch#4, loss = 0.27165979147, acc = 92.18800354%%\n",
      "Accuracy on validation after epoch#4, loss = 0.285378545523, acc = 92.1100006104%%\n",
      "Accuracy on training after epoch#5, loss = 0.270777732134, acc = 92.1920013428%%\n",
      "Accuracy on validation after epoch#5, loss = 0.285684973001, acc = 92.1100006104%%\n",
      "Accuracy on training after epoch#6, loss = 0.269952207804, acc = 92.2239990234%%\n",
      "Accuracy on validation after epoch#6, loss = 0.285997837782, acc = 92.0599975586%%\n",
      "Accuracy on training after epoch#7, loss = 0.269180655479, acc = 92.2539978027%%\n",
      "Accuracy on validation after epoch#7, loss = 0.286313563585, acc = 92.0499954224%%\n",
      "Accuracy on training after epoch#8, loss = 0.268457204103, acc = 92.2620010376%%\n",
      "Accuracy on validation after epoch#8, loss = 0.286630481482, acc = 92.0799942017%%\n",
      "Accuracy on training after epoch#9, loss = 0.267773836851, acc = 92.283996582%%\n",
      "Accuracy on validation after epoch#9, loss = 0.286947399378, acc = 92.0599975586%%\n"
     ]
    }
   ],
   "source": [
    "modelB = MnistLogisticB()\n",
    "fit(model, x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use optim module\n",
    "Now we make use of Adam optimizer from optim module and use it instead of manually updaing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB2 = MnistLogisticB()\n",
    "optimizer = optim.SGD(modelB2.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitB(model, opt, x_train, y_train, x_valid, y_valid, bs = 64):\n",
    "    n, num_feats = x_train.shape\n",
    "    with torch.no_grad():\n",
    "        print (\"Accuracy on training on initial weights = {}%%\".\n",
    "               format(loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "        print (\"Accuracy on validation  on initial weights = {}%%\".\n",
    "               format( loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for i in range(n/bs):\n",
    "            b_start = i*bs\n",
    "            b_end = min(n, (i+1)*bs)\n",
    "            xb = x_train[b_start:b_end]\n",
    "            yb = y_train[b_start:b_end]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print (\"Accuracy on training after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "            print (\"Accuracy on validation after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training on initial weights = 2.28835773468%%\n",
      "Accuracy on validation  on initial weights = 2.28492593765%%\n",
      "Accuracy on training after epoch#0, loss = 0.371194839478, acc = 89.59400177%%\n",
      "Accuracy on validation after epoch#0, loss = 0.340248942375, acc = 90.7900009155%%\n",
      "Accuracy on training after epoch#1, loss = 0.33239492774, acc = 90.675994873%%\n",
      "Accuracy on validation after epoch#1, loss = 0.309105068445, acc = 91.5599975586%%\n",
      "Accuracy on training after epoch#2, loss = 0.314870983362, acc = 91.1699981689%%\n",
      "Accuracy on validation after epoch#2, loss = 0.295534074306, acc = 91.7099990845%%\n",
      "Accuracy on training after epoch#3, loss = 0.304248064756, acc = 91.4459991455%%\n",
      "Accuracy on validation after epoch#3, loss = 0.287535250187, acc = 91.8899993896%%\n",
      "Accuracy on training after epoch#4, loss = 0.296892702579, acc = 91.6819992065%%\n",
      "Accuracy on validation after epoch#4, loss = 0.28215688467, acc = 92.0199966431%%\n",
      "Accuracy on training after epoch#5, loss = 0.291392236948, acc = 91.8860015869%%\n",
      "Accuracy on validation after epoch#5, loss = 0.278256893158, acc = 92.1199951172%%\n",
      "Accuracy on training after epoch#6, loss = 0.287057161331, acc = 91.9980010986%%\n",
      "Accuracy on validation after epoch#6, loss = 0.275285214186, acc = 92.1999969482%%\n",
      "Accuracy on training after epoch#7, loss = 0.283521980047, acc = 92.1240005493%%\n",
      "Accuracy on validation after epoch#7, loss = 0.272942364216, acc = 92.2900009155%%\n",
      "Accuracy on training after epoch#8, loss = 0.280553907156, acc = 92.202003479%%\n",
      "Accuracy on validation after epoch#8, loss = 0.271044939756, acc = 92.3399963379%%\n",
      "Accuracy on training after epoch#9, loss = 0.278013586998, acc = 92.2680053711%%\n",
      "Accuracy on validation after epoch#9, loss = 0.269477844238, acc = 92.4099960327%%\n"
     ]
    }
   ],
   "source": [
    "fitB(modelB2, optimizer, x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use dataset\n",
    "Now we implement a dataset to provide an iterator on mini-batches of mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "modelB3 = MnistLogisticB()\n",
    "optimizer = optim.SGD(modelB3.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitC(model, opt, train_ds, valid_ds, bs = 64):\n",
    "    n, num_feats = x_train.shape\n",
    "    with torch.no_grad():\n",
    "        print (\"Accuracy on training on initial weights = {}%%\".\n",
    "               format(loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "        print (\"Accuracy on validation  on initial weights = {}%%\".\n",
    "               format( loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for i in range(n/bs):\n",
    "            b_start = i*bs\n",
    "            b_end = min(n, (i+1)*bs)\n",
    "            xb, yb = train_ds[b_start:b_end]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print (\"Accuracy on training after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "            print (\"Accuracy on validation after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training on initial weights = 2.31765246391%%\n",
      "Accuracy on validation  on initial weights = 2.31621360779%%\n",
      "Accuracy on training after epoch#0, loss = 0.370389610529, acc = 89.6539993286%%\n",
      "Accuracy on validation after epoch#0, loss = 0.339587301016, acc = 90.8399963379%%\n",
      "Accuracy on training after epoch#1, loss = 0.331941872835, acc = 90.6319961548%%\n",
      "Accuracy on validation after epoch#1, loss = 0.308749049902, acc = 91.5499954224%%\n",
      "Accuracy on training after epoch#2, loss = 0.314577132463, acc = 91.1240005493%%\n",
      "Accuracy on validation after epoch#2, loss = 0.295317023993, acc = 91.7599945068%%\n",
      "Accuracy on training after epoch#3, loss = 0.304043233395, acc = 91.4540023804%%\n",
      "Accuracy on validation after epoch#3, loss = 0.287397742271, acc = 91.9799957275%%\n",
      "Accuracy on training after epoch#4, loss = 0.296744644642, acc = 91.6940002441%%\n",
      "Accuracy on validation after epoch#4, loss = 0.282068908215, acc = 92.1199951172%%\n",
      "Accuracy on training after epoch#5, loss = 0.29128241539, acc = 91.8659973145%%\n",
      "Accuracy on validation after epoch#5, loss = 0.27820032835, acc = 92.1699981689%%\n",
      "Accuracy on training after epoch#6, loss = 0.286976635456, acc = 91.9840011597%%\n",
      "Accuracy on validation after epoch#6, loss = 0.275252014399, acc = 92.2799987793%%\n",
      "Accuracy on training after epoch#7, loss = 0.283457279205, acc = 92.0960006714%%\n",
      "Accuracy on validation after epoch#7, loss = 0.272923231125, acc = 92.3099975586%%\n",
      "Accuracy on training after epoch#8, loss = 0.28050339222, acc = 92.1780014038%%\n",
      "Accuracy on validation after epoch#8, loss = 0.271036684513, acc = 92.3600006104%%\n",
      "Accuracy on training after epoch#9, loss = 0.277973562479, acc = 92.2779998779%%\n",
      "Accuracy on validation after epoch#9, loss = 0.269477933645, acc = 92.4499969482%%\n"
     ]
    }
   ],
   "source": [
    "fitC(modelB3, optimizer, train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using dataLoader\n",
    "Now we move from dataset to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitC(model, opt, train_dl, valid_ds, bs = 64):\n",
    "    n, num_feats = x_train.shape\n",
    "    with torch.no_grad():\n",
    "        print (\"Accuracy on training on initial weights = {}%%\".\n",
    "               format(loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "        print (\"Accuracy on validation  on initial weights = {}%%\".\n",
    "               format( loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print (\"Accuracy on training after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_train), y_train), 100*accuracy(model(x_train), y_train)))\n",
    "            print (\"Accuracy on validation after epoch#{}, loss = {}, acc = {}%%\".\n",
    "                   format(e, loss_func(model(x_valid), y_valid), 100*accuracy(model(x_valid), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB4 = MnistLogisticB()\n",
    "optimizer = optim.SGD(modelB4.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training on initial weights = 2.33358883858%%\n",
      "Accuracy on validation  on initial weights = 2.3331785202%%\n",
      "Accuracy on training after epoch#0, loss = 0.373415708542, acc = 89.560005188%%\n",
      "Accuracy on validation after epoch#0, loss = 0.340746074915, acc = 90.8699951172%%\n",
      "Accuracy on training after epoch#1, loss = 0.333442568779, acc = 90.5800018311%%\n",
      "Accuracy on validation after epoch#1, loss = 0.308996260166, acc = 91.5199966431%%\n",
      "Accuracy on training after epoch#2, loss = 0.315651535988, acc = 91.1520004272%%\n",
      "Accuracy on validation after epoch#2, loss = 0.295408040285, acc = 91.7299957275%%\n",
      "Accuracy on training after epoch#3, loss = 0.304965376854, acc = 91.4479980469%%\n",
      "Accuracy on validation after epoch#3, loss = 0.287493348122, acc = 91.939994812%%\n",
      "Accuracy on training after epoch#4, loss = 0.297607511282, acc = 91.6620025635%%\n",
      "Accuracy on validation after epoch#4, loss = 0.282211720943, acc = 92.0199966431%%\n",
      "Accuracy on training after epoch#5, loss = 0.292118161917, acc = 91.8280029297%%\n",
      "Accuracy on validation after epoch#5, loss = 0.278400659561, acc = 92.0699996948%%\n",
      "Accuracy on training after epoch#6, loss = 0.287805944681, acc = 91.9459991455%%\n",
      "Accuracy on validation after epoch#6, loss = 0.275505125523, acc = 92.2099990845%%\n",
      "Accuracy on training after epoch#7, loss = 0.284284025431, acc = 92.0540008545%%\n",
      "Accuracy on validation after epoch#7, loss = 0.27322474122, acc = 92.2699966431%%\n",
      "Accuracy on training after epoch#8, loss = 0.281334072351, acc = 92.1620025635%%\n",
      "Accuracy on validation after epoch#8, loss = 0.271380275488, acc = 92.3699951172%%\n",
      "Accuracy on training after epoch#9, loss = 0.278804689646, acc = 92.2439956665%%\n",
      "Accuracy on validation after epoch#9, loss = 0.269857019186, acc = 92.4199981689%%\n"
     ]
    }
   ],
   "source": [
    "fitC(modelB4, optimizer, train_dl, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2073, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(modelB4(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final concise model training code\n",
    "Now we have a few simple for loops using iterable dataloaders, optimizer and a train/validation dataset.\n",
    "The code is very small and boilderplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    return loss.sum(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, optimizer, train_dl, valid_dl, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, F.cross_entropy, xb, yb, optimizer)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss_batch(model, F.cross_entropy, xb, yb) for xb, yb in valid_dl])\n",
    "            val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB5 = MnistLogisticB()\n",
    "optimizer = optim.SGD(modelB5.parameters(), lr=0.1)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.3405073434591293)\n",
      "(1, 0.30897782959938047)\n",
      "(2, 0.2954883773326874)\n",
      "(3, 0.28762315254211424)\n",
      "(4, 0.28236833958625795)\n",
      "(5, 0.2785716407299042)\n",
      "(6, 0.27568455071449277)\n",
      "(7, 0.273408664894104)\n",
      "(8, 0.2715660556793213)\n",
      "(9, 0.2700433075904846)\n",
      "(10, 0.2687642114639282)\n",
      "(11, 0.26767549929618834)\n",
      "(12, 0.26673869175910947)\n",
      "(13, 0.26592519211769106)\n",
      "(14, 0.2652132611274719)\n",
      "(15, 0.26458611397743226)\n",
      "(16, 0.2640304989337921)\n",
      "(17, 0.26353586401939394)\n",
      "(18, 0.2630936748027802)\n",
      "(19, 0.26269691305160525)\n"
     ]
    }
   ],
   "source": [
    "fitModel(modelB5, optimizer, train_dl, valid_dl, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change to a convolutional neural network\n",
    "So far we have been using a simple FFNN for our training on MNIST.\n",
    "Now we use a convolutional neural network for the same task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTCnnModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.4456400409698487)\n",
      "(1, 1.0719625202178955)\n",
      "(2, 0.7578116257667542)\n",
      "(3, 0.6269843022346496)\n",
      "(4, 0.5948671291351318)\n",
      "(5, 0.4989111172676086)\n",
      "(6, 0.43818114252090457)\n",
      "(7, 0.38737517499923707)\n",
      "(8, 0.3479220549583435)\n",
      "(9, 0.3352505264282227)\n",
      "(10, 0.32151167039871215)\n",
      "(11, 0.3127714056968689)\n",
      "(12, 0.3074798121452332)\n",
      "(13, 0.2995388467788696)\n",
      "(14, 0.29109762592315674)\n",
      "(15, 0.2853382635116577)\n",
      "(16, 0.2816294466018677)\n",
      "(17, 0.27824177160263064)\n",
      "(18, 0.27821094923019407)\n",
      "(19, 0.25935887784957884)\n"
     ]
    }
   ],
   "source": [
    "cnnModel = MNISTCnnModel()\n",
    "optimizer = optim.SGD(cnnModel.parameters(), lr=0.1)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "\n",
    "fitModel(cnnModel, optimizer, train_dl, valid_dl, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.25000814361572266)\n",
      "(1, 0.24423124761581422)\n",
      "(2, 0.23760965995788574)\n",
      "(3, 0.23419155502319336)\n",
      "(4, 0.23063741731643678)\n",
      "(5, 0.22694143991470336)\n",
      "(6, 0.22101668949127198)\n",
      "(7, 0.21495990791320801)\n",
      "(8, 0.21049903516769408)\n",
      "(9, 0.20609152460098268)\n",
      "(10, 0.2027543080329895)\n",
      "(11, 0.20033662834167482)\n",
      "(12, 0.19601401987075806)\n",
      "(13, 0.19358204517364502)\n",
      "(14, 0.19125787258148194)\n",
      "(15, 0.18804359922409059)\n",
      "(16, 0.18614826498031617)\n",
      "(17, 0.18414234256744386)\n",
      "(18, 0.18174046354293824)\n",
      "(19, 0.17900956983566285)\n"
     ]
    }
   ],
   "source": [
    "fitModel(cnnModel, optimizer, train_dl, valid_dl, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set is : 94.63%\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy on validation set is : %0.2f%%\" % (100* accuracy(cnnModel(x_valid), y_valid).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.1768877561569214)\n",
      "(1, 0.1750524906158447)\n",
      "(2, 0.17338106422424315)\n",
      "(3, 0.17132014513015748)\n",
      "(4, 0.17026012935638427)\n",
      "(5, 0.16909880599975585)\n",
      "(6, 0.16835674467086792)\n",
      "(7, 0.1672633810043335)\n",
      "(8, 0.1670738037109375)\n",
      "(9, 0.16595254144668578)\n",
      "(10, 0.16492825660705565)\n",
      "(11, 0.16363085355758666)\n",
      "(12, 0.1628287091255188)\n",
      "(13, 0.16206137685775757)\n",
      "(14, 0.16102219009399413)\n",
      "(15, 0.1609912805557251)\n",
      "(16, 0.15978328847885132)\n",
      "(17, 0.15864411211013793)\n",
      "(18, 0.1584832880973816)\n",
      "(19, 0.15792025680541993)\n",
      "Accuracy on validation set is : 95.46%\n"
     ]
    }
   ],
   "source": [
    "fitModel(cnnModel, optimizer, train_dl, valid_dl, 20)\n",
    "print (\"Accuracy on validation set is : %0.2f%%\" % (100* accuracy(cnnModel(x_valid), y_valid).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training set is : 95.50%\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy on Training set is : %0.2f%%\" % (100* accuracy(cnnModel(x_train), y_train).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
